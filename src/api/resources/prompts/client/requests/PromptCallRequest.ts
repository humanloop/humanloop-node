/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as Humanloop from "../../../../index";

/**
 * @example
 *     {}
 */
export interface PromptCallRequest {
    /**
     * A specific Version ID of the Prompt to log to.
     */
    versionId?: string;
    /**
     * Name of the Environment identifying a deployed version to log to.
     */
    environment?: string;
    /** Path of the Prompt, including the name, which is used as a unique identifier. */
    path?: string;
    /** ID for an existing Prompt to update. */
    id?: string;
    /** Details of your Prompt. A new Prompt version will be created if the provided details are new. */
    prompt?: Humanloop.PromptKernelRequest;
    /** The messages passed to the to provider chat endpoint. */
    messages?: Humanloop.ChatMessage[];
    /**
     * Controls how the model uses tools. The following options are supported:
     * - `'none'` means the model will not call any tool and instead generates a message; this is the default when no tools are provided as part of the Prompt.
     * - `'auto'` means the model can decide to call one or more of the provided tools; this is the default when tools are provided as part of the Prompt.
     * - `'required'` means the model can decide to call one or more of the provided tools.
     * - `{'type': 'function', 'function': {name': <TOOL_NAME>}}` forces the model to use the named function.
     */
    toolChoice?: Humanloop.PromptCallRequestToolChoice;
    /** Unique identifier for the Session to associate the Log to. Allows you to record multiple Logs to a Session (using an ID kept by your internal systems) by passing the same `session_id` in subsequent log requests. */
    sessionId?: string;
    /** Unique identifier for the parent Log in a Session. Should only be provided if `session_id` is provided. If provided, the Log will be nested under the parent Log within the Session. */
    parentId?: string;
    /** The inputs passed to the prompt template. */
    inputs?: Record<string, unknown>;
    /** Identifies where the model was called from. */
    source?: string;
    /** Any additional metadata to record. */
    metadata?: Record<string, unknown>;
    /** Whether the request/response payloads will be stored on Humanloop. */
    save?: boolean;
    /** Unique identifier for the Datapoint that this Log is derived from. This can be used by Humanloop to associate Logs to Evaluations. If provided, Humanloop will automatically associate this Log to Evaluations that require a Log for this Datapoint-Version pair. */
    sourceDatapointId?: string;
    /** Array of Batch Ids that this log is part of. Batches are used to group Logs together for offline Evaluations */
    batches?: string[];
    /** End-user ID related to the Log. */
    user?: string;
    /** The name of the Environment the Log is associated to. */
    promptCallRequestEnvironment?: string;
    /** API keys required by each provider to make API calls. The API keys provided here are not stored by Humanloop. If not specified here, Humanloop will fall back to the key saved to your organization. */
    providerApiKeys?: Humanloop.ProviderApiKeys;
    /** The number of generations. */
    numSamples?: number;
    /** If true, tokens will be sent as data-only server-sent events. If num_samples > 1, samples are streamed back independently. */
    stream?: boolean;
    /** Whether to return the inputs in the response. If false, the response will contain an empty dictionary under inputs. This is useful for reducing the size of the response. Defaults to true. */
    returnInputs?: boolean;
    /** Include the log probabilities of the top n tokens in the provider_response */
    logprobs?: number;
    /** The suffix that comes after a completion of inserted text. Useful for completions that act like inserts. */
    suffix?: string;
}
